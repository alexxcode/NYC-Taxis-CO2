#### 1. Python
- **Descripción**: Python es un lenguaje de programación interpretado, con fuerte soporte para la integración y la orientación a objetos. Su simplicidad y flexibilidad lo han convertido en una opción preferida para análisis de datos, ciencia de datos y desarrollo de software.
- **Uso en el Proyecto**: Será utilizado para analizar grandes conjuntos de datos de tráfico, calidad del aire y sonora, aprovechando librerías como Pandas para la manipulación y análisis de datos estructurados, y Scikit-learn para el desarrollo de modelos de machine learning. Python nos permitirá procesar y analizar eficientemente los datos, así como desarrollar algoritmos predictivos y de clasificación necesarios para entender las dinámicas del tráfico y su impacto ambiental.

#### 2. Google Cloud BigQuery
- **Descripción**: BigQuery es un servicio de almacén de datos en la nube de Google, que ofrece una ejecución rápida de consultas SQL sobre grandes datasets. Se destaca por su capacidad de manejar petabytes de datos y su modelo de precios basado en el uso.
- **Uso en el Proyecto**: Utilizaremos BigQuery para consolidar y analizar grandes volúmenes de datos de diferentes fuentes. Su capacidad para manejar consultas complejas y grandes conjuntos de datos nos permitirá identificar patrones y tendencias en el tráfico y la contaminación, así como correlacionar estos datos con la calidad del aire y otros factores ambientales.

#### 3. Google Cloud AI Platform
- **Descripción**: Es una suite de servicios y herramientas que facilitan a los desarrolladores y científicos de datos el desarrollo, entrenamiento y despliegue de modelos de machine learning.
- **Uso en el Proyecto**: Emplearemos AI Platform para desarrollar y entrenar modelos de machine learning, aprovechando sus capacidades de procesamiento de alto rendimiento y su integración con herramientas de análisis y almacenamiento de datos. Esto nos permitirá implementar modelos predictivos y analíticos complejos, fundamentales para entender y predecir el impacto del tráfico en la contaminación.

#### 4. Google Sheets
- **Descripción**: Google Sheets es una herramienta de hojas de cálculo en línea que permite la colaboración en tiempo real. Es ampliamente utilizado para el análisis de datos debido a su accesibilidad y funcionalidad de integración.
- **Uso en el Proyecto**: Será utilizado para la recopilación y análisis colaborativo de datos financieros y operativos. Su integración con otras herramientas de Google Cloud facilitará la manipulación y visualización de datos, permitiendo compartir resultados y análisis en tiempo real con el equipo y los stakeholders.

#### 5. Google Cloud Dataflow
- **Descripción**: Dataflow es un servicio totalmente gestionado para procesar datos en tiempo real y por lotes. Ofrece un modelo de programación simplificado para desarrollar aplicaciones de procesamiento de datos y es altamente escalable.
- **Uso en el Proyecto**: Dataflow será utilizado para procesar y transformar datos de múltiples fuentes de manera eficiente, facilitando tareas de ETL y preparación de datos para su análisis posterior. Su capacidad para manejar grandes volúmenes de datos y procesamiento en tiempo real será crucial para mantener actualizados nuestros análisis y dashboards.

#### 6. Google Data Studio
- **Descripción**: Data Studio es una herramienta de visualización de datos que permite convertir los datos en informes interactivos y dashboards. Ofrece conectividad con varias fuentes de datos y permite una fácil interpretación de los datos.
- **Uso en el Proyecto**: Usaremos Data Studio para crear dashboards e informes interactivos que resuman nuestros hallazgos y análisis. Esto facilitará la comunicación de insights complejos a los stakeholders de manera comprensible y atractiva.

#### 7. Google Cloud Datalab
- **Descripción**: Datalab es un entorno interactivo basado en Jupyter que facilita el análisis y la visualización de datos complejos en Google Cloud.
- **Uso en el Proyecto**: Proporcionará un entorno flexible para el análisis exploratorio de datos, visualización y desarrollo de modelos de machine learning. Su integración con otras herramientas de Google Cloud permitirá un flujo de trabajo eficiente y una fácil exploración de los datos.

#### 8. Google Cloud Storage
- **Descripción**: Es un servicio de almacenamiento de objetos en la nube que ofrece durabilidad y escalabilidad. Permite guardar grandes cantidades de datos no estructurados.
- **Uso en el Proyecto**: Cloud Storage será utilizado para almacenar de manera segura y eficiente los grandes volúmenes de datos recopilados durante el proyecto, desde datos brutos hasta resultados procesados y modelos de machine learning.

#### 9. Google Cloud Dataprep
- **Descripción**: Dataprep es una herramienta de servicio inteligente para visualizar, limpiar y preparar datos para el análisis.
- **Uso en el Proyecto**: Facilitará la limpieza y transformación de los datos recopilados, asegurando que sean precisos y estén listos para el análisis. Su interfaz intuitiva y capacidades de automatización simplificarán el proceso de preparación de datos.

#### 10. Google App Engine
- **Descripción**: Es una plataforma como servicio (PaaS) que permite a los desarrolladores crear y desplegar aplicaciones en la infraestructura de Google.
- **Uso en el Proyecto**: Desarrollaremos y desplegaremos aplicaciones web para interactuar con los modelos de datos y presentar los resultados. App Engine nos proporcionará un entorno de hosting escalable y gestionado para estas aplicaciones.

#### 11. Google Kubernetes Engine
- **Descripción**: Es un servicio de orquestación de contenedores para la ejecución de aplicaciones en contenedores en un entorno de cluster.
- **Uso en el Proyecto**: Kubernetes Engine nos permitirá desplegar y escalar aplicaciones y servicios de manera eficiente, gestionando automáticamente la infraestructura subyacente.

#### 12. Google Workspace
- **Descripción**: Conjunto de herramientas de colaboración y productividad en la nube que incluye Gmail, Docs, Drive, Calendars y más.
- **Uso en el Proyecto**: Será utilizado para la colaboración en equipo, la gestión de documentos, presentaciones y hojas de cálculo, facilitando la comunicación y el trabajo coordinado entre los miembros del equipo.

#### 13. Github
- **Descripción**: Es un servicio web de hosting para el control de versiones y la colaboración en proyectos de software.
- **Uso en el Proyecto**: Se empleará para la gestión del código fuente, seguimiento de cambios, colaboración en el desarrollo y documentación del proyecto, garantizando un flujo de trabajo organizado y eficiente en el desarrollo de software y análisis de datos.

Cada una de estas tecnologías ha sido cuidadosamente seleccionada para abordar aspectos específicos del proyecto, desde el análisis y procesamiento de datos hasta la colaboración y presentación de resultados, asegurando un enfoque integral y eficiente para el análisis de tráfico y la contaminación en NYC.

## 12. Cronograma

| Actividad                                       | Lunes | Martes | Miércoles | Jueves | Viernes | Sprints    |
| ---------------------------------------------- | ----- | ------ | --------- | ------ | ------- | ---------- |
| **SEMANA 1**                                   |       |        |           |        |         | **Sprint 1** |
| Entendimiento de la situación actual           |   x   |   x    |    x      |   x    |         |            |
| Definición de objetivos                        |       |        |    x      |        |         | **Sprint 1** |
| Delimitación del alcance                      |       |        |    x      |        |         | **Sprint 1** |
| Desarrollo de KPIs                            |   x   |   x    |    x      |   x    |         |            |
| Creación del repositorio en Github            |       |        |           |   x    |   x     | **Sprint 1** |
| Solución propuesta                            |   x   |   x    |    x      |   x    |         |            |
| Documentación del alcance del proyecto        |   x   |   x    |    x      |   x    |         |            |
| EDA de los datos                              |   x   |   x    |    x      |   x    |         |            |
| Análisis preliminar de calidad de datos       |   x   |   x    |    x      |   x    |         |            |
| **SEMANA 2**                                   |       |        |           |        |         | **Sprint 2** |
| ETL completo                                   |   x   |        |           |        |         |            |
| Estructura de datos implementada (DW, DL, etc.)|   x   |   x    |           |        |         |            |
| Pipeline ETL automatizado                      |   x   |   x    |           |        |         |            |
| Diseño del Modelo ER                           |   x   |   x    |           |        |         |            |
| Análisis de datos de muestra                   |   x   |   x    |           |        |         |            |
| MVP/Prueba de Concepto de Dashboard/Producto ML|   x   |   x    |           |        |         |            |
| Documentación y reporte realizado              |       |   x    |    x      |        |         | **Sprint 2** |
| **SEMANA 3**                                   |       |        |           |        |         | **Sprint 3** |
| Dashboard final                                |   x   |   x    |           |        |         |            |
| Producto/s de ML                               |   x   |   x    |           |        |         |            |
| Diseño de Reportes/Dashboards                  |   x   |   x    |           |        |         |            |
| Modelos de ML en producción                   |       |        |    x      |   x    |         | **Sprint 3** |
| Selección del modelo, feature engineering      |       |        |    x      |   x    |         | **Sprint 3** |
| Informe de análisis                            |       |   x    |           |        |         | **Sprint 3** |
| Preparación de video del proyecto              |       |        |           |   x    |         | **Sprint 3** |
